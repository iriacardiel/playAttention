{
  "compute_device": "cuda",
  "tokenizer": "CharTokenizer",
  "vocab_size": 65,
  "seq_size": 256,
  "batch_size": 64,
  "n_embd": 384,
  "n_head": 6,
  "n_layer": 6,
  "dropout": 0.2,
  "training_steps": 5000,
  "lr": 0.0003,
  "val_loss_steps": 100,
  "eval_interval": 100,
  "train_val_ratio": 0.9
}